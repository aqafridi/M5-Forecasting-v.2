{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "from transformer.DataAggregator import DataAggregator\n",
    "from transformer.Dataformator import DataFormator\n",
    "from transformer.ImputeMean import ImputeMean\n",
    "from transformer.TrainTestSplit import TrainTestSplit\n",
    "import utils\n",
    "import numpy as np\n",
    "import json\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from configs.space import space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"./data/sales_train_validation.csv\")\n",
    "calender =pd.read_csv(\"./data/calendar.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aggregator = DataAggregator(sales)\n",
    "aggregated_data = data_aggregator.aggregate([\"store_id\",\"dept_id\"],\"sum\")\n",
    "data_formator =DataFormator(aggregated_data,calender)\n",
    "data = data_formator.format_data('store_id','dept_id')\n",
    "impute_mean =ImputeMean(data)\n",
    "data = impute_mean.replace_zero_with_mean()\n",
    "tts = TrainTestSplit( data, test_size=0.3, random_state=0,shuffle=False)\n",
    "X_train_, X_test_, y_train_, y_test_ = tts.split_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Space for Xgboost data preparation\n",
    "The link to papers is given below in the notebook, for The approch used in this model data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sequence_length = 1 #The forecasting horizon\n",
    "test_size = 0.30\n",
    "# for data preparation for xgboost\n",
    "hyperparameters = {\n",
    "    \"in_length\" : 1, # =target_sequence_length, forecasting horizon length\n",
    "    \"step_size\" : 4, # window size\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for best Parameters Model tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best ={}\n",
    "\n",
    "for i in data.columns:\n",
    "    y_train_data_ = pd.DataFrame()\n",
    "    y_test_data_ = pd.DataFrame()\n",
    "    y_train_data_[i] = y_train_[i]\n",
    "    y_test_data_[i] = y_test_[i]\n",
    "    \n",
    "    x_train, y_train,x_test, y_test = utils.prepare_data_for_xgb(\n",
    "                                    y_train_data_,y_test_data_,\n",
    "                                    hyperparameters[\"in_length\"],hyperparameters[\"step_size\"],\n",
    "                                    target_sequence_length\n",
    "                                                            )\n",
    "    def objective(params):\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model = MultiOutputRegressor(model).fit(x_train, y_train)\n",
    "        \n",
    "        # train_forecasts = model.predict(x_train)\n",
    "        test_forecasts = model.predict(x_test)\n",
    "        mse = mean_absolute_error(y_test, test_forecasts)\n",
    "        # print(f'Test MAE: { mse}')\n",
    "        # print(\"Mean test data value: {}\".format(np.mean(y_test)))\n",
    "        return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "    # optimize hyperparameters using Hyperopt's Tree-structured Parzen Estimator (TPE) algorithm\n",
    "    print(f\"Training .......\\n model_{i} \")\n",
    "    best[\"best_param_{0}\".format(i)] = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20)\n",
    "\n",
    "    print(best[\"best_param_{0}\".format(i)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_to_json('xgb_best_params',best,'w')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with best parameters Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best =utils.read_from_json('xgb_best_params',mode=\"r\")\n",
    "best.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model={}\n",
    "\n",
    "for i in data.columns:\n",
    "    y_train_data_ = pd.DataFrame()\n",
    "    y_test_data_ = pd.DataFrame()\n",
    "    y_train_data_[i] = y_train_[i]\n",
    "    y_test_data_[i] = y_test_[i]\n",
    "    \n",
    "    x_train, y_train,x_test, y_test = utils.prepare_data_for_xgb(\n",
    "                                    y_train_data_,y_test_data_,\n",
    "                                    hyperparameters[\"in_length\"],hyperparameters[\"step_size\"],\n",
    "                                    target_sequence_length\n",
    "                                                            )\n",
    "    \n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        gamma= best[f\"best_param_{i}\"]['gamma'],\n",
    "        learning_rate= best[f\"best_param_{i}\"]['learning_rate'],\n",
    "        max_depth= best[f\"best_param_{i}\"]['max_depth'],\n",
    "        n_estimators= best[f\"best_param_{i}\"]['n_estimators'],\n",
    "        reg_alpha= best[f\"best_param_{i}\"]['reg_alpha'],\n",
    "        reg_lambda= best[f\"best_param_{i}\"]['reg_lambda'],\n",
    "        subsample= best[f\"best_param_{i}\"]['subsample']\n",
    "        )\n",
    "\n",
    "    trained_model[\"model_{0}\".format(i)] = MultiOutputRegressor(model).fit(x_train, y_train)\n",
    "    print(f\"trained_model   :{i}\")\n",
    "    # train_forecasts = trained_model[\"model_{0}\".format(i)].predict(x_train)\n",
    "    test_forecasts = trained_model[\"model_{0}\".format(i)].predict(x_test)\n",
    "    test_mae = mean_absolute_error(y_test, test_forecasts)\n",
    "    print(f'Test MAE: { test_mae}')\n",
    "    # print(\"Mean test data value: {}\".format(np.mean(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trained_model['model_CA_1_FOODS_1']\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refrence of papers for the used approch: \n",
    "https://arxiv.org/abs/1603.02754  &    \n",
    "https://arxiv.org/abs/2101.02118\n",
    "#### Refrence to site for data preparing steps:\n",
    "https://towardsdatascience.com/multi-step-time-series-forecasting-with-xgboost-65d6820bec39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
